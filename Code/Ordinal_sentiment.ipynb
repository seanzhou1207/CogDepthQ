{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ordinal regression](https://en.wikipedia.org/wiki/Ordinal_regression) is a classification method for categories on an ordinal scale -- e.g. [1, 2, 3, 4, 5] or [G, PG, PG-13, R].  This notebook implements ordinal regression using the method of [Frank and Hal 2001](https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf), which transforms a k-multiclass classifier into k-1 binary classifiers (each of which predicts whether a data point is above a threshold in the ordinal scale -- e.g., whether a movie is \"higher\" than PG).  This method can be used with any binary classification method that outputs probabilities; here L2-regularizaed binary logistic regression is used.\n",
    "\n",
    "This notebook trains a model (on `train.txt`), optimizes L2 regularization strength on `dev.txt`, and evaluates performance on `test.txt`.  Reports test accuracy with 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TQTT9x-6d2JI"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import operator\n",
    "import nltk\n",
    "import math\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4KuVSCSqlUX",
    "outputId": "f4cf377b-6d74-473c-a945-828fa09bae92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\15527\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ordinal_data(filename, ordering):\n",
    "    \"\"\"\n",
    "    Split the input file into X and Y component\n",
    "    Input\n",
    "        filename(str)\n",
    "        ordering(list of str)\n",
    "    Output\n",
    "        X(list): list of all the questions\n",
    "        Y(list): One-hot encoding of Y\n",
    "        orig_Y: list of all the labels\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    orig_Y=[]\n",
    "    for _ in ordering:\n",
    "        Y.append([])\n",
    "        \n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        # for each row\n",
    "        for line in file:\n",
    "            cols = line.split(\"\\t\")\n",
    "            label = cols[2].lstrip().rstrip()\n",
    "            text = cols[3]\n",
    "            \n",
    "            X.append(text)\n",
    "            orig_Y.append(label)\n",
    "\n",
    "            index=ordering.index(label)\n",
    "            for i in range(len(ordering)):\n",
    "                if index > i:\n",
    "                    Y[i].append(1)\n",
    "                else:\n",
    "                    Y[i].append(0)\n",
    "                    \n",
    "    return X, Y, orig_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalClassifier:\n",
    "\n",
    "    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
    "        self.ordinal_values=ordinal_values\n",
    "        self.feature_vocab = {}\n",
    "        self.feature_method = feature_method\n",
    "        self.min_feature_count=2\n",
    "        self.log_regs = [None]* (len(self.ordinal_values)-1)\n",
    "\n",
    "        self.trainY=trainY\n",
    "        self.devY=devY\n",
    "        self.testY=testY\n",
    "        \n",
    "        self.orig_trainY=orig_trainY\n",
    "        self.orig_devY=orig_devY\n",
    "        self.orig_testY=orig_testY\n",
    "        \n",
    "        self.trainX = self.process(trainX, training=True)\n",
    "        self.devX = self.process(devX, training=False)\n",
    "        self.testX = self.process(testX, training=False)\n",
    "\n",
    "    # Featurize entire dataset\n",
    "    def featurize(self, data):\n",
    "        featurized_data = []\n",
    "        for text in data:\n",
    "            feats = self.feature_method(text)\n",
    "            featurized_data.append(feats)\n",
    "        return featurized_data\n",
    "\n",
    "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
    "    def process(self, X_data, training = False):\n",
    "        \n",
    "        data = self.featurize(X_data)\n",
    "\n",
    "        if training:\n",
    "            fid = 0\n",
    "            feature_doc_count = Counter()\n",
    "            for feats in data:\n",
    "                for feat in feats:\n",
    "                    feature_doc_count[feat]+= 1\n",
    "\n",
    "            for feat in feature_doc_count:\n",
    "                if feature_doc_count[feat] >= self.min_feature_count:\n",
    "                    self.feature_vocab[feat] = fid\n",
    "                    fid += 1\n",
    "\n",
    "        F = len(self.feature_vocab)\n",
    "        D = len(data)\n",
    "        X = sparse.dok_matrix((D, F))\n",
    "        for idx, feats in enumerate(data):\n",
    "            for feat in feats:\n",
    "                if feat in self.feature_vocab:\n",
    "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        (D,F) = self.trainX.shape\n",
    "        # fit the model for each level??\n",
    "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
    "            best_dev_accuracy=0\n",
    "            best_model=None\n",
    "            for C in [0.1, 1, 10, 100]:\n",
    "                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
    "                log_reg.fit(self.trainX, self.trainY[idx])\n",
    "                # score is define as R^2\n",
    "                training_accuracy = log_reg.score(self.trainX, self.trainY[idx])\n",
    "                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n",
    "                if development_accuracy > best_dev_accuracy:\n",
    "                    best_dev_accuracy=development_accuracy\n",
    "                    best_model=log_reg\n",
    "                # print(\"Method: combiner function, C: %s, Features: %s, Train score: %.3f, Dev score: %.3f\" % \n",
    "                #       (C, F, training_accuracy, development_accuracy))\n",
    "                # print(\"Method: combiner function, C: %s, Features: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % \n",
    "                #       (C, F, sum(log_reg.predict(self.trainX)==self.trainY[idx])/500, sum(log_reg.predict(self.devX)==self.devY[idx])/100))\n",
    "            self.log_regs[idx]=best_model\n",
    "        \n",
    "    def test(self):\n",
    "        cor=tot=0\n",
    "        counts=Counter()\n",
    "        preds=[None]*(len(self.ordinal_values)-1)\n",
    "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
    "            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n",
    "        \n",
    "        preds=np.array(preds)\n",
    "            \n",
    "        for data_point in range(len(preds[0])):\n",
    "            ordinal_preds=np.zeros(len(self.ordinal_values))\n",
    "            for ordinal in range(len(self.ordinal_values)-1):\n",
    "                if ordinal == 0:\n",
    "                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n",
    "                else:\n",
    "                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n",
    "\n",
    "            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n",
    "\n",
    "            prediction=np.argmax(ordinal_preds)\n",
    "            counts[prediction]+=1\n",
    "            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n",
    "                cor+=1\n",
    "            tot+=1\n",
    "\n",
    "        return cor/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_intervals(accuracy, n, significance_level):\n",
    "    critical_value=(1-significance_level)/2\n",
    "    z_alpha=-1*norm.ppf(critical_value)\n",
    "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
    "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(trainingFile, devFile, testFile, ordinal_values):\n",
    "\n",
    "\n",
    "    trainX, trainY, orig_trainY=load_ordinal_data(trainingFile, ordinal_values)\n",
    "    devX, devY, orig_devY=load_ordinal_data(devFile, ordinal_values)\n",
    "    testX, testY, orig_testY=load_ordinal_data(testFile, ordinal_values)\n",
    "    simple_classifier = OrdinalClassifier(ordinal_values, combiner_function, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
    "    simple_classifier.train()\n",
    "    accuracy=simple_classifier.test()\n",
    "\n",
    "    lower, upper=confidence_intervals(accuracy, len(testY[0]), .95)\n",
    "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_featurize(text):\n",
    "    feats = {}\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        if word in feats:\n",
    "            feats[word] += 1\n",
    "        else:\n",
    "            feats[word] = 1\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "\n",
    "from afinn import Afinn\n",
    "def afinn_sentiment(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name,\n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "\n",
    "    feats = {}\n",
    "    # BEGIN SOLUTION\n",
    "    afinn = Afinn()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "      feats[i] = afinn.score(sentence)\n",
    "\n",
    "    # END SOLUTION\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "def bigram(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name,\n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "\n",
    "    feats = {}\n",
    "    # BEGIN SOLUTION\n",
    "    words = nltk.word_tokenize(text)\n",
    "    trigrams = [' '.join(tg) for tg in list(nltk.bigrams(words))]\n",
    "    # END SOLUTION\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\15527\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# No effect\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "def Vader_sentiment(text):\n",
    "    feats = {}\n",
    "    feats[\"pos\"] = 0\n",
    "    feats[\"neg\"] = 0\n",
    "    feats[\"neu\"] = 0\n",
    "    feats[\"compound\"] = 0\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    for sentence in sentences:\n",
    "        score = sia.polarity_scores(sentence)\n",
    "        feats[\"pos\"] += score[\"pos\"]\n",
    "        feats[\"neg\"] += score [\"neg\"]\n",
    "        feats[\"neu\"] += score [\"neu\"]\n",
    "        feats[\"compound\"] += score [\"compound\"]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result in a lower accuracy\n",
    "import liwc\n",
    "\n",
    "# import requests\n",
    "# url = 'https://raw.githubusercontent.com/chun-hu/conversation-modeling/master/LIWC2007_English100131.dic'\n",
    "# r = requests.get(url)\n",
    "# with open('LIWC2007_English100131.dic', 'wb') as f:\n",
    "#     f.write(r.content)\n",
    "\n",
    "\n",
    "def liwc_pos_type(text):\n",
    "    # Here the `feats` dict should contain the features -- the key should be the feature name,\n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "\n",
    "    feats = {}\n",
    "    words = nltk.word_tokenize(text)\n",
    "    dictionary, category_names = liwc.read_dic(\"LIWC2007_English100131.dic\")\n",
    "\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        if word in dictionary:\n",
    "            for category in dictionary[word]:\n",
    "                if category in feats:\n",
    "                    feats[category] += 1\n",
    "                else:\n",
    "                    feats[category] = 1\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No effect\n",
    "def question_word_diction(text):\n",
    "        question_word_list = ['what', 'where', 'when','how','why','did','do','does','have','has','am','is','are','can','could','may','would','will','should'\n",
    "\"didn't\",\"doesn't\",\"haven't\",\"isn't\",\"aren't\",\"can't\",\"couldn't\",\"wouldn't\",\"won't\",\"shouldn't\",'?']\n",
    "        feats = {}\n",
    "        words = nltk.word_tokenize(text)\n",
    "        for word in words:\n",
    "            if word.lower() in feats:\n",
    "                  feats[word.lower()] += 1\n",
    "            elif word.lower() in question_word_list:\n",
    "                  feats[word.lower()] = 1\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combiner_function(text):\n",
    "\n",
    "    # Here the `all_feats` dict should contain the features -- the key should be the feature name,\n",
    "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
    "    # at the moment, all 4 of: bag of words and your 3 original features are handed off to the combined model\n",
    "    # update the values within [bag_of_words, feature1, feature2, feature3] to change this.\n",
    "\n",
    "    all_feats={}\n",
    "    for feature in [bow_featurize, bigram]:\n",
    "        all_feats.update(feature(text))\n",
    "    return all_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for best dev model: 0.570, 95% CIs: [0.473 0.667]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingFile = \"../Data/train.txt\"\n",
    "devFile = \"../Data/dev.txt\"\n",
    "testFile = \"../Data/test.txt\"\n",
    "    \n",
    "# ordinal values must be in order *as strings* from smallest to largest, e.g.:\n",
    "# ordinal_values=[\"G\", \"PG\", \"PG-13\", \"R\"]\n",
    "\n",
    "ordinal_values=[\"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "run(trainingFile, devFile, testFile, ordinal_values)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
