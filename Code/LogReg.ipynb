{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2-regularized logistic regression for binary or multiclass classification; trains a model (on `train.txt`), optimizes L2 regularization strength on `dev.txt`, and evaluates performance on `test.txt`.  Reports test accuracy with 95% confidence intervals and prints out the strongest coefficients for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4KuVSCSqlUX",
    "outputId": "f4cf377b-6d74-473c-a945-828fa09bae92",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/seanzhou/opt/anaconda3/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to /Users/seanzhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.22.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: jinja2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: setuptools in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (61.2.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.4)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader punkt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TQTT9x-6d2JI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/seanzhou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import operator\n",
    "import nltk\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "from Utils import *    # Get all nlp featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols = line.split(\"\\t\")\n",
    "            idd = cols[0]\n",
    "            label = cols[2].lstrip().rstrip()\n",
    "            text = cols[3]\n",
    "\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CGiM8qQiJOBU"
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, feature_method, trainX, trainY, devX, devY, testX, testY):\n",
    "        self.feature_vocab = {}\n",
    "        self.feature_method = feature_method\n",
    "        self.min_feature_count=2\n",
    "        self.log_reg = None\n",
    "\n",
    "        self.trainY=trainY\n",
    "        self.devY=devY\n",
    "        self.testY=testY\n",
    "        \n",
    "        self.trainX = self.process(trainX, training=True)\n",
    "        self.devX = self.process(devX, training=False)\n",
    "        self.testX = self.process(testX, training=False)\n",
    "\n",
    "    # Featurize entire dataset\n",
    "    def featurize(self, data):\n",
    "        featurized_data = []\n",
    "        for text in data:\n",
    "            feats = self.feature_method(text)\n",
    "            featurized_data.append(feats)\n",
    "        return featurized_data\n",
    "\n",
    "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
    "    def process(self, X_data, training = False):\n",
    "        \n",
    "        data = self.featurize(X_data)\n",
    "\n",
    "        if training:\n",
    "            fid = 0\n",
    "            feature_doc_count = Counter()\n",
    "            for feats in data:\n",
    "                for feat in feats:\n",
    "                    feature_doc_count[feat]+= 1\n",
    "\n",
    "            for feat in feature_doc_count:\n",
    "                if feature_doc_count[feat] >= self.min_feature_count:\n",
    "                    self.feature_vocab[feat] = fid\n",
    "                    fid += 1\n",
    "\n",
    "        F = len(self.feature_vocab)\n",
    "        D = len(data)\n",
    "        X = sparse.dok_matrix((D, F))\n",
    "        for idx, feats in enumerate(data):\n",
    "            for feat in feats:\n",
    "                if feat in self.feature_vocab:\n",
    "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "    # Train model and evaluate on held-out data\n",
    "    def train(self):\n",
    "        (D,F) = self.trainX.shape\n",
    "        best_dev_accuracy=0\n",
    "        best_model=None\n",
    "        for C in [0.1, 1, 5, 10, 100]:\n",
    "            #self.log_reg = linear_model.LogisticRegression(C = C, penalty='l1', \n",
    "                                                            #solver='liblinear', max_iter=1000)\n",
    "            self.log_reg = linear_model.LogisticRegression(C = C, penalty='l2', max_iter=1000)\n",
    "            self.log_reg.fit(self.trainX, self.trainY)\n",
    "            training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n",
    "            development_accuracy = self.log_reg.score(self.devX, self.devY)\n",
    "            if development_accuracy > best_dev_accuracy:\n",
    "                best_dev_accuracy=development_accuracy\n",
    "                best_model=self.log_reg\n",
    "\n",
    "#             print(\"C: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (C, training_accuracy, development_accuracy))\n",
    "        self.log_reg=best_model\n",
    "        \n",
    "\n",
    "    def test(self):\n",
    "        return self.log_reg.score(self.testX, self.testY)\n",
    "        \n",
    "\n",
    "    def printWeights(self, n=10):\n",
    "\n",
    "        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n",
    "        for k in self.feature_vocab:\n",
    "            reverse_vocab[self.feature_vocab[k]]=k\n",
    "\n",
    "        # binary\n",
    "        if len(self.log_reg.classes_) == 2:\n",
    "              weights=self.log_reg.coef_[0]\n",
    "\n",
    "              cat=self.log_reg.classes_[1]\n",
    "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "              cat=self.log_reg.classes_[0]\n",
    "              for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n",
    "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "              print()\n",
    "\n",
    "        # multiclass\n",
    "        else:\n",
    "          for i, cat in enumerate(self.log_reg.classes_):\n",
    "\n",
    "              weights=self.log_reg.coef_[i]\n",
    "\n",
    "            #   for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
    "            #       print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
    "            #   print()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_intervals(accuracy, n, significance_level):\n",
    "    critical_value=(1-significance_level)/2\n",
    "    z_alpha=-1*norm.ppf(critical_value)\n",
    "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
    "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(trainingFile, devFile, testFile):\n",
    "    trainX, trainY=load_data(trainingFile)\n",
    "    devX, devY=load_data(devFile)\n",
    "    testX, testY=load_data(testFile)\n",
    "    \n",
    "    simple_classifier = Classifier(combiner_function, trainX, trainY, devX, devY, testX, testY)\n",
    "    simple_classifier.train()\n",
    "    accuracy=simple_classifier.test()\n",
    "    \n",
    "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
    "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
    "\n",
    "    simple_classifier.printWeights()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for best dev model: 0.500, 95% CIs: [0.402 0.598]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanzhou/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "trainingFile = \"../Data/train.txt\"\n",
    "devFile = \"../Data/dev.txt\"\n",
    "testFile = \"../Data/test.txt\"\n",
    "    \n",
    "run(trainingFile, devFile, testFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# # Load the English NLP model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def get_max_depth(token, current_depth=0):\n",
    "#     \"\"\"Recursively find the maximum depth of the dependency tree.\"\"\"\n",
    "#     if not list(token.children):\n",
    "#         return current_depth\n",
    "#     return max(get_max_depth(child, current_depth + 1) for child in token.children)\n",
    "\n",
    "# def calculate_syntactic_complexity(sentence):\n",
    "#     \"\"\"Calculate the syntactic complexity of a sentence by finding the max depth of its parse tree.\"\"\"\n",
    "#     doc = nlp(sentence)\n",
    "#     root = next(tok for tok in doc if tok.dep_ == 'ROOT')  # Find the root of the sentence\n",
    "#     max_depth = get_max_depth(root)\n",
    "#     return max_depth\n",
    "\n",
    "# # Example sentence\n",
    "# sentence = \"Can you explain how economic policies, influenced by global events, impact market dynamics considering the global economic environment?\"\n",
    "# sentence2 = \"And can you maybe discuss the seasonality in the business and beyond, of course, the Q2 maintenance and how Dresden might impact that?\"\n",
    "# sentence3 = \"I do want to dig into the incremental rental margins just for the 45\\% \\in the quarter can you maybe just help us understand what the weather impact may have been or the reposition expense or even if you guys had to face some sizable fleet repair expenses, fix up some of these units that are coming out of the shale plays?\"\n",
    "# complexity = calculate_syntactic_complexity(sentence3)\n",
    "# print(f\"The syntactic complexity of the sentence is {complexity}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "162b6b064e165ad366d1bd4cdc631c4691b039cb551eb2d47403b16e997dbe09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
